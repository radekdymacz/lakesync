---
title: Introduction
description: LakeSync — sync any data source to a local working set.
---

LakeSync is an open-source sync engine for TypeScript apps. Your app or agent declares what data it needs, and LakeSync syncs a filtered subset to local SQLite — queryable, offline-capable, and always up to date. If you can read from a data source, it can be a LakeSync adapter.

## How It Works

1. **Adapters** connect to data sources — Postgres, BigQuery, S3/R2, CloudWatch, or anything you write an adapter for
2. **Sync rules** define what data flows to each consumer — filtered by JWT claims, columns, or temporal ranges
3. **The gateway** evaluates rules and routes data between sources and consumers
4. **Local SQLite** gives each consumer a queryable working set with zero-latency reads

Web apps get offline support. AI agents get a local copy to reason over. Dashboards get exactly the slice they need. Same protocol, any source.

## Adapters

| Adapter | Use case |
|---------|----------|
| **Postgres / MySQL** | Operational OLTP data, familiar SQL tooling |
| **BigQuery** | Analytics-scale queries, managed and serverless |
| **S3 / R2 (Iceberg)** | Massive scale on object storage, open format |
| **Anything else** | Implement the adapter interface — CloudWatch, Stripe, custom APIs |

The `DatabaseAdapter` interface (`insertDeltas`, `queryDeltasSince`, `getLatestState`, `ensureSchema`) handles SQL-like sources. The `LakeAdapter` interface (`putObject`, `getObject`, `listObjects`, `deleteObject`) handles object storage. Adapters are both sources and destinations, enabling cross-backend flows.

## Key Features

- **Pluggable adapters** — Any data source you can read from becomes a LakeSync source. The adapter interface is the extension point.
- **Sync rules** — Declarative rules define what data flows where. The DSL is the core primitive for both web apps and AI agents.
- **Column-level LWW** — Conflicts resolved per-column, not per-row. Concurrent edits to different fields never overwrite each other.
- **Offline-first** — The full working set lives in local SQLite (via sql.js WASM). Changes queue and push when connectivity returns.
- **Hybrid Logical Clocks** — Every mutation timestamped with a branded `HLCTimestamp` (48-bit wall clock + 16-bit counter) for causal ordering.
- **Result-based error handling** — Public APIs return `Result<T, E>` instead of throwing.

## Packages

| Package | Description |
|---------|-------------|
| `@lakesync/core` | HLC, Delta, Result, conflict resolution, sync rules, validation |
| `@lakesync/client` | LocalDB (sql.js), SyncCoordinator, transports, queues |
| `@lakesync/gateway` | In-memory sync gateway with push/pull protocol |
| `@lakesync/proto` | Protocol Buffer encoding/decoding for deltas |
| `@lakesync/adapter` | Storage adapters (S3/R2, Postgres, MySQL, BigQuery, Composite) |
| `@lakesync/parquet` | Parquet file reader/writer |
| `@lakesync/catalogue` | Iceberg catalogue management |
| `@lakesync/compactor` | Compaction, maintenance, and checkpoint generation |
| `@lakesync/analyst` | Schema evolution and analytics |
| `lakesync` | Unified package re-exporting all packages |
