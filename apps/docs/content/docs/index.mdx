---
title: Introduction
description: LakeSync — sync any data source to a local working set.
---

LakeSync is an open-source TypeScript sync engine. Pluggable adapters connect to any data source. Declarative sync rules define what data flows where. Consumers get a local SQLite working set with offline support and column-level conflict resolution.

## How It Works

1. **Adapters** connect to data sources — Postgres, BigQuery, S3/R2, or anything you implement the interface for
2. **Sync rules** define what data flows to each consumer — bucket-based filtering with `eq`/`in` operators and JWT claim references
3. **The gateway** evaluates rules and routes data between adapters
4. **Local SQLite** gives each consumer a queryable working set with zero-latency reads and offline support

## Adapters

Two interfaces abstract all data sources. Adapters are both sources and destinations.

| Adapter | Interface | Details |
|---------|-----------|---------|
| **Postgres / MySQL** | `DatabaseAdapter` | `insertDeltas`, `queryDeltasSince`, `getLatestState`, `ensureSchema` |
| **BigQuery** | `DatabaseAdapter` | Idempotent MERGE inserts, INT64 HLC precision, clustered by `table` + `hlc` |
| **S3 / R2 (Iceberg)** | `LakeAdapter` | `putObject`, `getObject`, `listObjects`, `deleteObject` — Parquet + Iceberg table format |
| **Custom** | Either | Implement the interface for any readable data source. `CompositeAdapter` routes to multiple backends. |

## Key Features

- **Pluggable adapters** — `DatabaseAdapter` for SQL-like sources, `LakeAdapter` for object storage. Both are bidirectional. Cross-backend flows via sync rules.
- **Adapter-sourced pull** — Pull data from named source adapters (BigQuery, Postgres, etc.) directly into local SQLite. The gateway queries the adapter and applies sync rules before returning filtered deltas.
- **Sync rules DSL** — Declarative bucket-based filtering with `eq`/`in`/`neq`/`gt`/`lt`/`gte`/`lte` operators and `jwt:` claim references. Pure function evaluation via `filterDeltas()`.
- **Column-level LWW** — Conflicts resolved per-column, not per-row. Concurrent edits to different fields never overwrite each other.
- **Real-time sync** — WebSocket-based server-initiated broadcast. When any client pushes, others receive deltas in sub-100ms. Auto-reconnect with exponential backoff. HTTP polling as fallback.
- **Offline support** — Local SQLite via sql.js WASM. Persistent IndexedDB outbox survives page refreshes and process crashes. Automatic drain on reconnect.
- **Hybrid Logical Clocks** — Branded `HLCTimestamp` bigint (48-bit wall clock + 16-bit counter). Causal ordering with deterministic `clientId` tiebreaking.
- **Result-based error handling** — Public APIs return `Result<T, E>` instead of throwing.

## Packages

| Package | Description |
|---------|-------------|
| `@lakesync/core` | HLC, Delta, Result, conflict resolution, sync rules, validation |
| `@lakesync/client` | LocalDB (sql.js), SyncCoordinator, transports, queues |
| `@lakesync/gateway` | In-memory sync gateway with push/pull protocol |
| `@lakesync/gateway-server` | Self-hosted gateway server (Node.js/Bun) with HTTP + WebSocket |
| `@lakesync/proto` | Protocol Buffer encoding/decoding for deltas and broadcast frames |
| `@lakesync/adapter` | Storage adapters (S3/R2, Postgres, MySQL, BigQuery, Composite) |
| `@lakesync/parquet` | Parquet file reader/writer |
| `@lakesync/catalogue` | Iceberg catalogue management |
| `@lakesync/compactor` | Compaction, maintenance, and checkpoint generation |
| `@lakesync/analyst` | Schema evolution and analytics |
| `lakesync` | Unified package re-exporting all packages |
